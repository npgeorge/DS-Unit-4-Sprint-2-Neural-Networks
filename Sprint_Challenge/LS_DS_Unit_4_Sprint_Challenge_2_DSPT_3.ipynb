{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Simple Perceptron](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "    - Analyze and Compare\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Defining Neural Networks \n",
    "\n",
    "Write *your own* definitions for the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    " - A neuron in a nueral network is also known as a node is a set of inputs, weights, and a bias value. The output of a node is either observed or passed along to the next layer in the network.\n",
    "- **Input Layer:**\n",
    " - The input layer is the starting point for any nueral network. This layer receives the initial input from our data set. All of the remaining layers will be a derivative of the input layer.\n",
    "- **Hidden Layer:**\n",
    " - The hidden layer(s) comes after the input layer and can not be directly accessed. The hidden layers apply weights or transformations that produce an output specific to an intended result. The hidden layer(s) can only be accessed through the input layer. The \"Deep Learning\" phrase comes from a networks ability to have multiple layers. \n",
    "- **Output Layer:**\n",
    " - The output layer returns vector values in a format that is desired. An activation function is usually applied to achieve a desired transformation of data into a workable format.\n",
    "- **Activation Function:**\n",
    " - Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (“fired”) or not, based on whether each neuron's input is relevant for the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    " - It is the practice of fine-tuning the weights of a neural net based on the error rate or loss obtained in the previous epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    " - A simple perceptron takes inputs, that get passed to weights, those weights are then summed, a step function is applied, and an output is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>\n",
    "## 2. Simple Perceptron\n",
    "\n",
    "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our Dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\"Use this X & y in the following 2 models\"\n",
    "X = rng.randn(300, 2)\n",
    "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97873798, 2.2408932 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Perceptron\n",
    "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/500\n",
      "300/300 [==============================] - 0s 989us/sample - loss: 0.2588 - accuracy: 0.5467\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2584 - accuracy: 0.5500\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2581 - accuracy: 0.5433\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.2578 - accuracy: 0.5367\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.2575 - accuracy: 0.5333\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2572 - accuracy: 0.5300\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2570 - accuracy: 0.5333\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.2567 - accuracy: 0.5300\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2565 - accuracy: 0.5267\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2562 - accuracy: 0.5267\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.2560 - accuracy: 0.5233\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2558 - accuracy: 0.5267\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2556 - accuracy: 0.5233\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2554 - accuracy: 0.5167\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2552 - accuracy: 0.5167\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2551 - accuracy: 0.5167\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2549 - accuracy: 0.5133\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2548 - accuracy: 0.5133\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2545 - accuracy: 0.5133\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2544 - accuracy: 0.5133\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2543 - accuracy: 0.5133\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2541 - accuracy: 0.5100\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2540 - accuracy: 0.5100\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2538 - accuracy: 0.5100\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2537 - accuracy: 0.5067\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2536 - accuracy: 0.5067\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.2535 - accuracy: 0.5067\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2533 - accuracy: 0.5067\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2532 - accuracy: 0.5033\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2531 - accuracy: 0.4967\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2530 - accuracy: 0.4967\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2529 - accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2528 - accuracy: 0.5033\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2527 - accuracy: 0.4967\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2525 - accuracy: 0.4967\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2525 - accuracy: 0.4900\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2524 - accuracy: 0.4800\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2523 - accuracy: 0.4833\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2522 - accuracy: 0.4833\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 66us/sample - loss: 0.2521 - accuracy: 0.4833\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 132us/sample - loss: 0.2520 - accuracy: 0.4833\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2519 - accuracy: 0.4867\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2518 - accuracy: 0.4867\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2517 - accuracy: 0.4867\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2516 - accuracy: 0.4833\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2515 - accuracy: 0.4933\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2515 - accuracy: 0.4867\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2513 - accuracy: 0.4867\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2513 - accuracy: 0.4867\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2512 - accuracy: 0.4867\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2511 - accuracy: 0.4900\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2510 - accuracy: 0.4867\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2509 - accuracy: 0.4833\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2509 - accuracy: 0.4833\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.2508 - accuracy: 0.4833\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2507 - accuracy: 0.4833\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2506 - accuracy: 0.4900\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.2506 - accuracy: 0.4900\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2505 - accuracy: 0.4867\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2504 - accuracy: 0.4833\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2503 - accuracy: 0.4833\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2503 - accuracy: 0.4800\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.2502 - accuracy: 0.4900\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2502 - accuracy: 0.4933\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2501 - accuracy: 0.4967\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2501 - accuracy: 0.4967\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2500 - accuracy: 0.4967\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2500 - accuracy: 0.4933\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2499 - accuracy: 0.4900\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2498 - accuracy: 0.4900\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 138us/sample - loss: 0.2498 - accuracy: 0.4967\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2497 - accuracy: 0.4967\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2497 - accuracy: 0.4967\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 120us/sample - loss: 0.2496 - accuracy: 0.5000\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.2496 - accuracy: 0.5067\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2495 - accuracy: 0.5067\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2495 - accuracy: 0.5067\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2494 - accuracy: 0.5100\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2494 - accuracy: 0.5033\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2494 - accuracy: 0.5067\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2493 - accuracy: 0.5100\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2492 - accuracy: 0.5067\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.2492 - accuracy: 0.5133\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2492 - accuracy: 0.5167\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2491 - accuracy: 0.5233\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2491 - accuracy: 0.5233\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 115us/sample - loss: 0.2491 - accuracy: 0.5267\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.2490 - accuracy: 0.5267\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2489 - accuracy: 0.5267\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.2489 - accuracy: 0.5300\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2489 - accuracy: 0.5333\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2488 - accuracy: 0.5333\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2488 - accuracy: 0.5333\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.2487 - accuracy: 0.5333\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2487 - accuracy: 0.5333\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.2487 - accuracy: 0.5400\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2486 - accuracy: 0.5400\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2486 - accuracy: 0.5400\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2486 - accuracy: 0.5400\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2485 - accuracy: 0.5400\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2485 - accuracy: 0.5433\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.2485 - accuracy: 0.5500\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2484 - accuracy: 0.5500\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2484 - accuracy: 0.5500\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2484 - accuracy: 0.5567\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2483 - accuracy: 0.5600\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2483 - accuracy: 0.5600\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2483 - accuracy: 0.5633\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.53 - 0s 103us/sample - loss: 0.2482 - accuracy: 0.5633\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.2482 - accuracy: 0.5633\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2482 - accuracy: 0.5633\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 127us/sample - loss: 0.2482 - accuracy: 0.5633\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2481 - accuracy: 0.5633\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2481 - accuracy: 0.5667\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2481 - accuracy: 0.5733\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2481 - accuracy: 0.5767\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2480 - accuracy: 0.5800\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 66us/sample - loss: 0.2480 - accuracy: 0.5800\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2480 - accuracy: 0.5833\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2480 - accuracy: 0.5900\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.2479 - accuracy: 0.5900\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2479 - accuracy: 0.6000\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2479 - accuracy: 0.6067\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2479 - accuracy: 0.6133\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2478 - accuracy: 0.6133\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2478 - accuracy: 0.6133\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2478 - accuracy: 0.6133\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2478 - accuracy: 0.6133\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2478 - accuracy: 0.6167\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2477 - accuracy: 0.6167\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2477 - accuracy: 0.6167\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2477 - accuracy: 0.6167\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2477 - accuracy: 0.6167\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2477 - accuracy: 0.6200\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2476 - accuracy: 0.6267\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2476 - accuracy: 0.6167\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2477 - accuracy: 0.6333\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2476 - accuracy: 0.6367\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2476 - accuracy: 0.6367\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2475 - accuracy: 0.6367\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2475 - accuracy: 0.6400\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2475 - accuracy: 0.6367\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2475 - accuracy: 0.6400\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2474 - accuracy: 0.6400\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2475 - accuracy: 0.6467\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.2474 - accuracy: 0.6467\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2474 - accuracy: 0.6467\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2474 - accuracy: 0.6467\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2474 - accuracy: 0.6467\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2474 - accuracy: 0.6467\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2473 - accuracy: 0.6500\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2473 - accuracy: 0.6533\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2473 - accuracy: 0.6533\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2473 - accuracy: 0.6533\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2473 - accuracy: 0.6533\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2473 - accuracy: 0.6533\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 127us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2472 - accuracy: 0.6533\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2471 - accuracy: 0.6567\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.2471 - accuracy: 0.6567\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2471 - accuracy: 0.6567\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2471 - accuracy: 0.6600\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2471 - accuracy: 0.6600\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2471 - accuracy: 0.6600\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2471 - accuracy: 0.6600\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2470 - accuracy: 0.6600\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2470 - accuracy: 0.6600\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2470 - accuracy: 0.6633\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2470 - accuracy: 0.6667\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2470 - accuracy: 0.6667\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 61us/sample - loss: 0.2470 - accuracy: 0.6667\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2470 - accuracy: 0.6667\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2469 - accuracy: 0.6667\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2469 - accuracy: 0.6667\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2469 - accuracy: 0.6633\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2469 - accuracy: 0.6667\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2469 - accuracy: 0.6667\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.2469 - accuracy: 0.6633\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2469 - accuracy: 0.6700\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2468 - accuracy: 0.6700\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.2469 - accuracy: 0.6733\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.2468 - accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2468 - accuracy: 0.6667\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2468 - accuracy: 0.6667\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2468 - accuracy: 0.6667\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2468 - accuracy: 0.6667\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2467 - accuracy: 0.6667\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2466 - accuracy: 0.6667\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2466 - accuracy: 0.6667\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2466 - accuracy: 0.6700\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 66us/sample - loss: 0.2466 - accuracy: 0.6700\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2466 - accuracy: 0.6700\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 60us/sample - loss: 0.2466 - accuracy: 0.6700\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2465 - accuracy: 0.6700\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2465 - accuracy: 0.6800\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2465 - accuracy: 0.6800\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 61us/sample - loss: 0.2465 - accuracy: 0.6800\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2465 - accuracy: 0.6767\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2465 - accuracy: 0.6733\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2464 - accuracy: 0.6767\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2463 - accuracy: 0.6767\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2463 - accuracy: 0.6767\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2463 - accuracy: 0.6767\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2463 - accuracy: 0.6767\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.2463 - accuracy: 0.6800\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2463 - accuracy: 0.6800\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 64us/sample - loss: 0.2462 - accuracy: 0.6767\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2462 - accuracy: 0.6767\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2462 - accuracy: 0.6767\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.2462 - accuracy: 0.6733\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2462 - accuracy: 0.6800\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2462 - accuracy: 0.6800\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2462 - accuracy: 0.6833\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.2461 - accuracy: 0.6800\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2461 - accuracy: 0.6833\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.2461 - accuracy: 0.6800\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.2461 - accuracy: 0.6867\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2461 - accuracy: 0.6833\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.2460 - accuracy: 0.6833\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2460 - accuracy: 0.6867\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2460 - accuracy: 0.6933\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2460 - accuracy: 0.6900\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2460 - accuracy: 0.6867\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2460 - accuracy: 0.6833\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.2459 - accuracy: 0.6833\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2459 - accuracy: 0.6833\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.2459 - accuracy: 0.6833\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2459 - accuracy: 0.6900\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2458 - accuracy: 0.6933\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2458 - accuracy: 0.6933\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2458 - accuracy: 0.6933\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2458 - accuracy: 0.6933\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2458 - accuracy: 0.6967\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2457 - accuracy: 0.6967\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2457 - accuracy: 0.6933\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2457 - accuracy: 0.6933\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2457 - accuracy: 0.6967\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.2457 - accuracy: 0.6967\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.2456 - accuracy: 0.6967\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2456 - accuracy: 0.6967\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2456 - accuracy: 0.6967\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2456 - accuracy: 0.7000\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 207us/sample - loss: 0.2455 - accuracy: 0.7000\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2455 - accuracy: 0.7000\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2455 - accuracy: 0.7033\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.2455 - accuracy: 0.7033\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2454 - accuracy: 0.7033\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2454 - accuracy: 0.6933\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2454 - accuracy: 0.6933\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2454 - accuracy: 0.6933\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.2454 - accuracy: 0.6933\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.2453 - accuracy: 0.6933\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 128us/sample - loss: 0.2453 - accuracy: 0.6933\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2453 - accuracy: 0.6967\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2453 - accuracy: 0.6967\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.2452 - accuracy: 0.6967\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2452 - accuracy: 0.7000\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 136us/sample - loss: 0.2452 - accuracy: 0.7033\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 144us/sample - loss: 0.2452 - accuracy: 0.7033\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 123us/sample - loss: 0.2451 - accuracy: 0.7033\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2451 - accuracy: 0.7033\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2451 - accuracy: 0.7000\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2450 - accuracy: 0.6967\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2450 - accuracy: 0.6933\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2450 - accuracy: 0.6933\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2449 - accuracy: 0.6933\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2449 - accuracy: 0.6933\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2449 - accuracy: 0.7000\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2449 - accuracy: 0.7000\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2448 - accuracy: 0.7033\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2448 - accuracy: 0.7033\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2448 - accuracy: 0.7033\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2447 - accuracy: 0.7033\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2447 - accuracy: 0.7033\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2447 - accuracy: 0.7033\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2447 - accuracy: 0.7033\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2446 - accuracy: 0.7000\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2446 - accuracy: 0.7033\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2445 - accuracy: 0.7033\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2445 - accuracy: 0.7033\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.2445 - accuracy: 0.7033\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2444 - accuracy: 0.7033\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 165us/sample - loss: 0.2444 - accuracy: 0.7033\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2444 - accuracy: 0.7033\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2443 - accuracy: 0.7033\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2443 - accuracy: 0.7033\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.2443 - accuracy: 0.7033\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.2442 - accuracy: 0.7033\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2442 - accuracy: 0.7033\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2441 - accuracy: 0.7033\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.2441 - accuracy: 0.7100\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2441 - accuracy: 0.7033\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2440 - accuracy: 0.7033\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2440 - accuracy: 0.7033\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2439 - accuracy: 0.7033\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2439 - accuracy: 0.7033\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2439 - accuracy: 0.7033\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2438 - accuracy: 0.7033\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 117us/sample - loss: 0.2438 - accuracy: 0.7100\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.2438 - accuracy: 0.7100\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2437 - accuracy: 0.7067\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 121us/sample - loss: 0.2437 - accuracy: 0.7033\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2436 - accuracy: 0.7000\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2436 - accuracy: 0.7000\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2435 - accuracy: 0.7000\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2435 - accuracy: 0.7000\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2435 - accuracy: 0.7033\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2434 - accuracy: 0.7067\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2433 - accuracy: 0.7033\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 57us/sample - loss: 0.2433 - accuracy: 0.7033\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2433 - accuracy: 0.7067\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2432 - accuracy: 0.7067\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2432 - accuracy: 0.7067\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2431 - accuracy: 0.7067\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2431 - accuracy: 0.7000\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2430 - accuracy: 0.7067\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2430 - accuracy: 0.7067\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2429 - accuracy: 0.7000\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 66us/sample - loss: 0.2429 - accuracy: 0.7000\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2428 - accuracy: 0.7000\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.2428 - accuracy: 0.6967\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2427 - accuracy: 0.6933\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2426 - accuracy: 0.6933\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.2426 - accuracy: 0.6967\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2425 - accuracy: 0.7000\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2425 - accuracy: 0.6967\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2424 - accuracy: 0.7000\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2424 - accuracy: 0.7000\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2423 - accuracy: 0.7033\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2423 - accuracy: 0.7067\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2422 - accuracy: 0.7067\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2422 - accuracy: 0.7067\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2421 - accuracy: 0.7000\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.2420 - accuracy: 0.7000\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2420 - accuracy: 0.7000\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 120us/sample - loss: 0.2419 - accuracy: 0.6933\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2418 - accuracy: 0.6933\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2418 - accuracy: 0.6933\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2417 - accuracy: 0.6933\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2417 - accuracy: 0.6933\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2416 - accuracy: 0.6933\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.78 - 0s 72us/sample - loss: 0.2415 - accuracy: 0.6933\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2415 - accuracy: 0.6967\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2414 - accuracy: 0.6967\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2413 - accuracy: 0.6933\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2413 - accuracy: 0.6933\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2412 - accuracy: 0.6933\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2411 - accuracy: 0.6933\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2411 - accuracy: 0.6967\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 115us/sample - loss: 0.2410 - accuracy: 0.6967\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2409 - accuracy: 0.6933\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2408 - accuracy: 0.6933\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.2408 - accuracy: 0.6967\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2407 - accuracy: 0.6967\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2406 - accuracy: 0.6967\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.68 - 0s 131us/sample - loss: 0.2406 - accuracy: 0.6933\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2405 - accuracy: 0.6900\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2404 - accuracy: 0.6933\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2403 - accuracy: 0.6933\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2403 - accuracy: 0.6933\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2402 - accuracy: 0.6967\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.62 - 0s 116us/sample - loss: 0.2401 - accuracy: 0.6967\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.2400 - accuracy: 0.6967\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2399 - accuracy: 0.6967\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2399 - accuracy: 0.6933\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.2398 - accuracy: 0.6933\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 127us/sample - loss: 0.2397 - accuracy: 0.6867\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 139us/sample - loss: 0.2396 - accuracy: 0.6900\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2396 - accuracy: 0.7000\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2395 - accuracy: 0.7000\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2394 - accuracy: 0.7000\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2393 - accuracy: 0.6967\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2392 - accuracy: 0.6967\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2391 - accuracy: 0.6967\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2391 - accuracy: 0.7000\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2390 - accuracy: 0.7000\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2389 - accuracy: 0.6933\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2388 - accuracy: 0.6967\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2387 - accuracy: 0.7000\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2386 - accuracy: 0.7000\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2385 - accuracy: 0.7000\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2385 - accuracy: 0.7000\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2384 - accuracy: 0.7000\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2383 - accuracy: 0.7000\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2382 - accuracy: 0.7000\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2381 - accuracy: 0.6967\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2380 - accuracy: 0.6967\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.2379 - accuracy: 0.7000\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2379 - accuracy: 0.7000\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2377 - accuracy: 0.6967\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2376 - accuracy: 0.6933\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2376 - accuracy: 0.6933\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2374 - accuracy: 0.6933\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2374 - accuracy: 0.6933\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2373 - accuracy: 0.6967\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.2372 - accuracy: 0.6900\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2371 - accuracy: 0.6900\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2370 - accuracy: 0.6900\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2369 - accuracy: 0.6900\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2368 - accuracy: 0.6900\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.2367 - accuracy: 0.6867\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2366 - accuracy: 0.6833\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.2365 - accuracy: 0.6833\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2364 - accuracy: 0.6900\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 61us/sample - loss: 0.2363 - accuracy: 0.6900\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2362 - accuracy: 0.6900\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2361 - accuracy: 0.6900\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 62us/sample - loss: 0.2360 - accuracy: 0.6900\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2358 - accuracy: 0.6933\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2357 - accuracy: 0.6900\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2356 - accuracy: 0.6900\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.2355 - accuracy: 0.6900\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.2354 - accuracy: 0.6900\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 55us/sample - loss: 0.2353 - accuracy: 0.6900\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2353 - accuracy: 0.6900\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.2351 - accuracy: 0.6900\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2350 - accuracy: 0.6933\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.2349 - accuracy: 0.6933\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 64us/sample - loss: 0.2348 - accuracy: 0.6900\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2347 - accuracy: 0.6900\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.2346 - accuracy: 0.6900\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2345 - accuracy: 0.6900\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.2344 - accuracy: 0.6900\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.2343 - accuracy: 0.6900\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2342 - accuracy: 0.6900\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2341 - accuracy: 0.6900\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2340 - accuracy: 0.6900\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2338 - accuracy: 0.6900\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2337 - accuracy: 0.6900\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2336 - accuracy: 0.6900\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.2335 - accuracy: 0.6900\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2334 - accuracy: 0.6900\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2333 - accuracy: 0.6900\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2332 - accuracy: 0.6900\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.2330 - accuracy: 0.6900\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2329 - accuracy: 0.6900\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2329 - accuracy: 0.6900\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2327 - accuracy: 0.6933\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2326 - accuracy: 0.6900\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.2325 - accuracy: 0.6900\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.2324 - accuracy: 0.6900\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2322 - accuracy: 0.6900\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2321 - accuracy: 0.6900\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2320 - accuracy: 0.6933\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2319 - accuracy: 0.6900\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.2318 - accuracy: 0.6900\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2317 - accuracy: 0.6900\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2315 - accuracy: 0.6900\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.2314 - accuracy: 0.6867\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2313 - accuracy: 0.6900\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2312 - accuracy: 0.6867\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2311 - accuracy: 0.6867\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.2310 - accuracy: 0.6867\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.2309 - accuracy: 0.6867\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 58us/sample - loss: 0.2307 - accuracy: 0.6900\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 59us/sample - loss: 0.2306 - accuracy: 0.6900\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2306 - accuracy: 0.6900\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2304 - accuracy: 0.6900\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2303 - accuracy: 0.6900\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.2301 - accuracy: 0.6900\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2300 - accuracy: 0.6900\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2299 - accuracy: 0.6900\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2298 - accuracy: 0.6900\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2297 - accuracy: 0.6900\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.2296 - accuracy: 0.6900\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2294 - accuracy: 0.6933\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2293 - accuracy: 0.6933\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2292 - accuracy: 0.6900\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2291 - accuracy: 0.6900\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.2290 - accuracy: 0.6900\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2288 - accuracy: 0.6867\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2287 - accuracy: 0.6867\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.2286 - accuracy: 0.6933\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2285 - accuracy: 0.6933\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.2284 - accuracy: 0.6933\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.2282 - accuracy: 0.6900\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.2281 - accuracy: 0.6900\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.2280 - accuracy: 0.6933\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.2280 - accuracy: 0.6933\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2278 - accuracy: 0.6900\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.2276 - accuracy: 0.6933\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.2275 - accuracy: 0.6900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a6d6fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequential modeling, order of added layers matters\n",
    "model1 = Sequential()\n",
    "\n",
    "#the order you add layers builds your architecture\n",
    "\n",
    "#input node\n",
    "model1.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "#output\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compiler\n",
    "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "h1 = model1.fit(X, y, epochs=500)\n",
    "h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "Now construct a multi-layer perceptron using Keras. Here are some architecture suggestions: \n",
    "- 2 Hidden Layers\n",
    "- 5-32 Neurons in the Hidden Layers\n",
    "- Your pick of activation function and optimizer\n",
    "- Incorporate the Callback function below into your model\n",
    "\n",
    "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. You must also monitor the metric 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > .99999):   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/500\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: 0.2501 - accuracy: 0.4733\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 135us/sample - loss: 0.2488 - accuracy: 0.5467\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.2481 - accuracy: 0.5867\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2469 - accuracy: 0.5267\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2462 - accuracy: 0.5267\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.2447 - accuracy: 0.5267\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.2438 - accuracy: 0.5267\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.2428 - accuracy: 0.5267\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.2418 - accuracy: 0.5267\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 115us/sample - loss: 0.2407 - accuracy: 0.5267\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.2393 - accuracy: 0.5900\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.2379 - accuracy: 0.6000\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2366 - accuracy: 0.6100\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2353 - accuracy: 0.6733\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.2337 - accuracy: 0.7000\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 115us/sample - loss: 0.2323 - accuracy: 0.6900\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 127us/sample - loss: 0.2305 - accuracy: 0.7167\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 171us/sample - loss: 0.2287 - accuracy: 0.7300\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2270 - accuracy: 0.7267\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.2254 - accuracy: 0.7200\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.2231 - accuracy: 0.7200\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.2212 - accuracy: 0.7267\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.2192 - accuracy: 0.7133\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2171 - accuracy: 0.7400\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2153 - accuracy: 0.7267\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.2136 - accuracy: 0.7100\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.2110 - accuracy: 0.7067\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.2093 - accuracy: 0.7133\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.2073 - accuracy: 0.7300\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.2057 - accuracy: 0.7267\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.2038 - accuracy: 0.7133\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.2030 - accuracy: 0.7033\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.2011 - accuracy: 0.7067\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.2004 - accuracy: 0.7100\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1984 - accuracy: 0.7133\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1974 - accuracy: 0.7033\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1969 - accuracy: 0.7000\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1953 - accuracy: 0.7067\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 120us/sample - loss: 0.1944 - accuracy: 0.7033\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.1939 - accuracy: 0.7033\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.1933 - accuracy: 0.7100\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1924 - accuracy: 0.7100\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1917 - accuracy: 0.7033\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.1916 - accuracy: 0.7033\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.1915 - accuracy: 0.7067\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1905 - accuracy: 0.7133\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1906 - accuracy: 0.7033\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.1897 - accuracy: 0.7100\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.1897 - accuracy: 0.7067\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.1896 - accuracy: 0.7100\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.1892 - accuracy: 0.7133\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.1894 - accuracy: 0.7033\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1891 - accuracy: 0.7067\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.1884 - accuracy: 0.7000\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.1889 - accuracy: 0.7067\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1886 - accuracy: 0.7100\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.1883 - accuracy: 0.7133\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1878 - accuracy: 0.7100\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1878 - accuracy: 0.7067\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1890 - accuracy: 0.7033\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.1875 - accuracy: 0.7100\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1878 - accuracy: 0.7100\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 117us/sample - loss: 0.1877 - accuracy: 0.7100\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.1876 - accuracy: 0.7167\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.1876 - accuracy: 0.7033\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1874 - accuracy: 0.7100\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.1874 - accuracy: 0.7000\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1870 - accuracy: 0.7133\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1874 - accuracy: 0.7167\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.1876 - accuracy: 0.7067\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.1867 - accuracy: 0.7100\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1867 - accuracy: 0.7067\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1871 - accuracy: 0.7167\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.1870 - accuracy: 0.7067\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.1867 - accuracy: 0.7067\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.1867 - accuracy: 0.7100\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1867 - accuracy: 0.7100\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1863 - accuracy: 0.7067\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1865 - accuracy: 0.7100\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1868 - accuracy: 0.7067\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.1863 - accuracy: 0.7100\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 63us/sample - loss: 0.1863 - accuracy: 0.7033\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1867 - accuracy: 0.7033\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1864 - accuracy: 0.7067\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.1864 - accuracy: 0.7100\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1860 - accuracy: 0.7133\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1860 - accuracy: 0.7100\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1860 - accuracy: 0.7000\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 128us/sample - loss: 0.1862 - accuracy: 0.7033\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1865 - accuracy: 0.7133\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1869 - accuracy: 0.7133\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1860 - accuracy: 0.7167\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.1857 - accuracy: 0.7067\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.1865 - accuracy: 0.7067\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 163us/sample - loss: 0.1863 - accuracy: 0.7067\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.1858 - accuracy: 0.7167\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1852 - accuracy: 0.7100\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1859 - accuracy: 0.7133\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1863 - accuracy: 0.7233\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.1857 - accuracy: 0.7167\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.1853 - accuracy: 0.7167\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1859 - accuracy: 0.7133\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1853 - accuracy: 0.7100\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1856 - accuracy: 0.7167\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1854 - accuracy: 0.7067\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1851 - accuracy: 0.7100\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.1854 - accuracy: 0.7167\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1849 - accuracy: 0.7133\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.1851 - accuracy: 0.7100\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.1847 - accuracy: 0.7067\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.1848 - accuracy: 0.7100\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.1856 - accuracy: 0.7233\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1850 - accuracy: 0.7167\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.1850 - accuracy: 0.7133\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1847 - accuracy: 0.7167\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.1846 - accuracy: 0.7133\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.1846 - accuracy: 0.7167\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1845 - accuracy: 0.7067\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: 0.1842 - accuracy: 0.7233\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 128us/sample - loss: 0.1840 - accuracy: 0.7167\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 299us/sample - loss: 0.1841 - accuracy: 0.7133\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 289us/sample - loss: 0.1845 - accuracy: 0.7133\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.1843 - accuracy: 0.7167\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 134us/sample - loss: 0.1838 - accuracy: 0.7200\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 143us/sample - loss: 0.1835 - accuracy: 0.7200\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 182us/sample - loss: 0.1837 - accuracy: 0.7167\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 119us/sample - loss: 0.1838 - accuracy: 0.7200\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 185us/sample - loss: 0.1836 - accuracy: 0.7200\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 150us/sample - loss: 0.1840 - accuracy: 0.7167\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1832 - accuracy: 0.7267\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 386us/sample - loss: 0.1832 - accuracy: 0.7167\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 277us/sample - loss: 0.1828 - accuracy: 0.7300\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.1832 - accuracy: 0.7267\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 114us/sample - loss: 0.1828 - accuracy: 0.7233\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.1832 - accuracy: 0.7233\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1827 - accuracy: 0.7333\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.1833 - accuracy: 0.7233\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.1826 - accuracy: 0.7233\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 133us/sample - loss: 0.1820 - accuracy: 0.7267\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.1822 - accuracy: 0.7300\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 114us/sample - loss: 0.1823 - accuracy: 0.7267\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.1821 - accuracy: 0.7233\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1821 - accuracy: 0.7333\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.1817 - accuracy: 0.7333\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 117us/sample - loss: 0.1813 - accuracy: 0.7267\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1809 - accuracy: 0.7300\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1811 - accuracy: 0.7333\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1804 - accuracy: 0.7333\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1808 - accuracy: 0.7333\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.1808 - accuracy: 0.7233\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1809 - accuracy: 0.7367\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.1801 - accuracy: 0.7333\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1819 - accuracy: 0.7300\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.1794 - accuracy: 0.7367\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.1798 - accuracy: 0.7267\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1792 - accuracy: 0.7467\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1791 - accuracy: 0.7400\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.1788 - accuracy: 0.7333\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.1780 - accuracy: 0.7433\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 126us/sample - loss: 0.1787 - accuracy: 0.7333\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.1785 - accuracy: 0.7267\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.1782 - accuracy: 0.7400\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.1773 - accuracy: 0.7433\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 136us/sample - loss: 0.1775 - accuracy: 0.7433\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.1776 - accuracy: 0.7300\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1770 - accuracy: 0.7367\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 120us/sample - loss: 0.1763 - accuracy: 0.7433\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1760 - accuracy: 0.7433\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1760 - accuracy: 0.7467\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 130us/sample - loss: 0.1755 - accuracy: 0.7433\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.1753 - accuracy: 0.7500\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.1752 - accuracy: 0.7533\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1744 - accuracy: 0.7467\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.1745 - accuracy: 0.7500\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.1738 - accuracy: 0.7600\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.1741 - accuracy: 0.7400\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 139us/sample - loss: 0.1740 - accuracy: 0.7433\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.1729 - accuracy: 0.7533\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1726 - accuracy: 0.7433\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1721 - accuracy: 0.7467\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.1723 - accuracy: 0.7500\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1716 - accuracy: 0.7500\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.1718 - accuracy: 0.7433\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1713 - accuracy: 0.7333\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1702 - accuracy: 0.7467\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1701 - accuracy: 0.7500\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1696 - accuracy: 0.7500\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1692 - accuracy: 0.7533\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1687 - accuracy: 0.7500\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1684 - accuracy: 0.7533\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1678 - accuracy: 0.7567\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.1673 - accuracy: 0.7567\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1667 - accuracy: 0.7533\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.1664 - accuracy: 0.7600\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1661 - accuracy: 0.7600\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1662 - accuracy: 0.7533\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.1650 - accuracy: 0.7700\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.1646 - accuracy: 0.7600\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 151us/sample - loss: 0.1642 - accuracy: 0.7533\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 118us/sample - loss: 0.1632 - accuracy: 0.7600\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.1625 - accuracy: 0.7600\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.1622 - accuracy: 0.7600\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1619 - accuracy: 0.7600\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 139us/sample - loss: 0.1614 - accuracy: 0.7733\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1613 - accuracy: 0.7733\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 123us/sample - loss: 0.1602 - accuracy: 0.7800\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.1594 - accuracy: 0.7667\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1588 - accuracy: 0.7567\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.1582 - accuracy: 0.7733\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.1576 - accuracy: 0.7767\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1570 - accuracy: 0.7700\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1562 - accuracy: 0.7667\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.1558 - accuracy: 0.7633\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.1550 - accuracy: 0.7800\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.1546 - accuracy: 0.7633\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.1533 - accuracy: 0.7700\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.1525 - accuracy: 0.7800\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1521 - accuracy: 0.7867\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1509 - accuracy: 0.7800\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1504 - accuracy: 0.7800\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.1494 - accuracy: 0.7800\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.1487 - accuracy: 0.7833\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1480 - accuracy: 0.7800\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1471 - accuracy: 0.7833\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1463 - accuracy: 0.7833\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1454 - accuracy: 0.7867\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.1450 - accuracy: 0.7800\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1434 - accuracy: 0.7967\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.1429 - accuracy: 0.7933\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.1420 - accuracy: 0.7967\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1409 - accuracy: 0.8000\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.1402 - accuracy: 0.8033\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.1398 - accuracy: 0.8100\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.1400 - accuracy: 0.8033\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1377 - accuracy: 0.7967\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.1363 - accuracy: 0.8067\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1357 - accuracy: 0.8133\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1346 - accuracy: 0.8100\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1338 - accuracy: 0.8133\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1327 - accuracy: 0.8167\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.1317 - accuracy: 0.8233\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1308 - accuracy: 0.8233\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 122us/sample - loss: 0.1307 - accuracy: 0.8233\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.1289 - accuracy: 0.8267\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.1278 - accuracy: 0.8267\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.1270 - accuracy: 0.8267\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.1257 - accuracy: 0.8267\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.1253 - accuracy: 0.8267\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.1237 - accuracy: 0.8333\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.1226 - accuracy: 0.8433\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1215 - accuracy: 0.8433\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.1202 - accuracy: 0.8433\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1194 - accuracy: 0.8433\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.1182 - accuracy: 0.8433\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.1171 - accuracy: 0.8333\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.1160 - accuracy: 0.8533\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.1148 - accuracy: 0.8433\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.1135 - accuracy: 0.8500\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.1125 - accuracy: 0.8467\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.1115 - accuracy: 0.8533\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.1104 - accuracy: 0.8600\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.1089 - accuracy: 0.8600\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.1085 - accuracy: 0.8400\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.1073 - accuracy: 0.8533\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 113us/sample - loss: 0.1060 - accuracy: 0.8633\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.1049 - accuracy: 0.8600\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.1037 - accuracy: 0.8633\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 62us/sample - loss: 0.1031 - accuracy: 0.8600\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.1017 - accuracy: 0.8667\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.1008 - accuracy: 0.8700\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.1005 - accuracy: 0.8700\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0986 - accuracy: 0.8733\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.0980 - accuracy: 0.8767\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.0965 - accuracy: 0.8800\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.0959 - accuracy: 0.8833\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.0953 - accuracy: 0.8667\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.0941 - accuracy: 0.8733\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0932 - accuracy: 0.8867\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.0926 - accuracy: 0.8800\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0903 - accuracy: 0.8800\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.0898 - accuracy: 0.8833\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.0886 - accuracy: 0.8733\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0879 - accuracy: 0.8733\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0867 - accuracy: 0.8833\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0862 - accuracy: 0.8900\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.0850 - accuracy: 0.8867\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.0842 - accuracy: 0.8900\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0831 - accuracy: 0.8967\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0825 - accuracy: 0.8933\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.0813 - accuracy: 0.8900\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.0810 - accuracy: 0.8967\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.0789 - accuracy: 0.9033\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0794 - accuracy: 0.8833\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.0781 - accuracy: 0.8867\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0766 - accuracy: 0.8967\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.0758 - accuracy: 0.9100\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0751 - accuracy: 0.9067\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0740 - accuracy: 0.9000\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0733 - accuracy: 0.9000\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.0728 - accuracy: 0.9100\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0716 - accuracy: 0.9100\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0705 - accuracy: 0.9000\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.0704 - accuracy: 0.9100\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.0691 - accuracy: 0.9100\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.0681 - accuracy: 0.9067\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.0681 - accuracy: 0.9067\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.0671 - accuracy: 0.9100\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 125us/sample - loss: 0.0658 - accuracy: 0.9167\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0654 - accuracy: 0.9233\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0645 - accuracy: 0.9100\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.0637 - accuracy: 0.9167\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0630 - accuracy: 0.9233\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0629 - accuracy: 0.9100\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.0619 - accuracy: 0.9133\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0621 - accuracy: 0.9267\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0604 - accuracy: 0.9200\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0598 - accuracy: 0.9167\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 116us/sample - loss: 0.0588 - accuracy: 0.9200\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0582 - accuracy: 0.9267\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0572 - accuracy: 0.9300\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0568 - accuracy: 0.9200\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0559 - accuracy: 0.9267\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.0561 - accuracy: 0.9400\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 68us/sample - loss: 0.0548 - accuracy: 0.9367\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.0540 - accuracy: 0.9333\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0537 - accuracy: 0.9333\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.0530 - accuracy: 0.9400\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.0526 - accuracy: 0.9400\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.0519 - accuracy: 0.9400\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.0525 - accuracy: 0.9300\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0504 - accuracy: 0.9433\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.0501 - accuracy: 0.9467\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0493 - accuracy: 0.9500\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0490 - accuracy: 0.9400\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0486 - accuracy: 0.9467\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.0481 - accuracy: 0.9500\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0480 - accuracy: 0.9533\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0471 - accuracy: 0.9467\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.0461 - accuracy: 0.9500\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0459 - accuracy: 0.9533\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0453 - accuracy: 0.9533\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0451 - accuracy: 0.9567\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0443 - accuracy: 0.9567\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0440 - accuracy: 0.9600\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0433 - accuracy: 0.9567\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 70us/sample - loss: 0.0429 - accuracy: 0.9600\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.0429 - accuracy: 0.9600\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.0417 - accuracy: 0.9667\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0415 - accuracy: 0.9667\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0409 - accuracy: 0.9667\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0405 - accuracy: 0.9667\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0408 - accuracy: 0.9633\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 61us/sample - loss: 0.0396 - accuracy: 0.9667\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 64us/sample - loss: 0.0395 - accuracy: 0.9667\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0393 - accuracy: 0.9667\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 71us/sample - loss: 0.0388 - accuracy: 0.9667\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0380 - accuracy: 0.9700\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0376 - accuracy: 0.9667\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 65us/sample - loss: 0.0377 - accuracy: 0.9667\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.0374 - accuracy: 0.9700\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 69us/sample - loss: 0.0366 - accuracy: 0.9700\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0372 - accuracy: 0.9633\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0360 - accuracy: 0.9700\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.0360 - accuracy: 0.9733\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.0350 - accuracy: 0.9700\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0349 - accuracy: 0.9667\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.0343 - accuracy: 0.9733\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.0341 - accuracy: 0.9700\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.0337 - accuracy: 0.9700\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0333 - accuracy: 0.9733\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.0332 - accuracy: 0.9700\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0334 - accuracy: 0.9700\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0326 - accuracy: 0.9733\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0320 - accuracy: 0.9767\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0320 - accuracy: 0.9733\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0315 - accuracy: 0.9733\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0312 - accuracy: 0.9733\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0310 - accuracy: 0.9733\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0313 - accuracy: 0.9733\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 76us/sample - loss: 0.0304 - accuracy: 0.9733\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0305 - accuracy: 0.9733\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.0296 - accuracy: 0.9733\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0299 - accuracy: 0.9733\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.0298 - accuracy: 0.9767\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0292 - accuracy: 0.9800\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0286 - accuracy: 0.9800\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.0285 - accuracy: 0.9800\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0281 - accuracy: 0.9833\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0278 - accuracy: 0.9800\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.0274 - accuracy: 0.9800\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 117us/sample - loss: 0.0273 - accuracy: 0.9800\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0271 - accuracy: 0.9800\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.0268 - accuracy: 0.9767\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.0265 - accuracy: 0.9833\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0263 - accuracy: 0.9833\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.0259 - accuracy: 0.9833\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 74us/sample - loss: 0.0258 - accuracy: 0.9833\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.0258 - accuracy: 0.9800\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.0254 - accuracy: 0.9867\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.0253 - accuracy: 0.9833\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0249 - accuracy: 0.9833\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0248 - accuracy: 0.9833\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.0250 - accuracy: 0.9800\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 88us/sample - loss: 0.0246 - accuracy: 0.9800\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.0242 - accuracy: 0.9867\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.0239 - accuracy: 0.9867\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.0236 - accuracy: 0.9867\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0234 - accuracy: 0.9867\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.0231 - accuracy: 0.9867\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0229 - accuracy: 0.9833\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.0230 - accuracy: 0.9867\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.0226 - accuracy: 0.9867\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 67us/sample - loss: 0.0224 - accuracy: 0.9867\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0223 - accuracy: 0.9867\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.0221 - accuracy: 0.9833\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.0218 - accuracy: 0.9867\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.0218 - accuracy: 0.9833\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.0222 - accuracy: 0.9867\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.0212 - accuracy: 0.9867\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 135us/sample - loss: 0.0217 - accuracy: 0.9800\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 79us/sample - loss: 0.0209 - accuracy: 0.9867\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0215 - accuracy: 0.9833\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0209 - accuracy: 0.9900\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 87us/sample - loss: 0.0207 - accuracy: 0.9900\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0203 - accuracy: 0.9833\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0203 - accuracy: 0.9833\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.0200 - accuracy: 0.9867\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0200 - accuracy: 0.9867\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.0196 - accuracy: 0.9833\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.0198 - accuracy: 0.9867\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.0195 - accuracy: 0.9867\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.0193 - accuracy: 0.9900\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.0191 - accuracy: 0.9933\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 110us/sample - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.0187 - accuracy: 0.9833\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.0184 - accuracy: 0.9833\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 191us/sample - loss: 0.0183 - accuracy: 0.9867\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0182 - accuracy: 0.9867\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0185 - accuracy: 0.9867\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 83us/sample - loss: 0.0182 - accuracy: 0.9900\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 64us/sample - loss: 0.0181 - accuracy: 0.9867\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0178 - accuracy: 0.9867\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.0179 - accuracy: 0.9900\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.0179 - accuracy: 0.9900\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.0178 - accuracy: 0.9933\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0172 - accuracy: 0.9900\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.0171 - accuracy: 0.9900\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0168 - accuracy: 0.9900\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0167 - accuracy: 0.9867\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.0166 - accuracy: 0.9900\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0166 - accuracy: 0.9900\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.0163 - accuracy: 0.9900\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.0163 - accuracy: 0.9867\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 143us/sample - loss: 0.0164 - accuracy: 0.9900\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.0159 - accuracy: 0.9900\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 121us/sample - loss: 0.0160 - accuracy: 0.9900\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0156 - accuracy: 0.9900\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0159 - accuracy: 0.9900\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 96us/sample - loss: 0.0155 - accuracy: 0.9900\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0156 - accuracy: 0.9900\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 129us/sample - loss: 0.0154 - accuracy: 0.9900\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 78us/sample - loss: 0.0152 - accuracy: 0.9900\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.0154 - accuracy: 0.9900\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.0150 - accuracy: 0.9933\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 120us/sample - loss: 0.0149 - accuracy: 0.9933\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 141us/sample - loss: 0.0150 - accuracy: 0.9900\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.0148 - accuracy: 0.9900\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.0147 - accuracy: 0.9933\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.0148 - accuracy: 0.9933\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 72us/sample - loss: 0.0147 - accuracy: 0.9900\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 125us/sample - loss: 0.0147 - accuracy: 0.9900\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 121us/sample - loss: 0.0144 - accuracy: 0.9967\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 112us/sample - loss: 0.0143 - accuracy: 0.9933\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 115us/sample - loss: 0.0140 - accuracy: 0.9933\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.0147 - accuracy: 0.9900\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 80us/sample - loss: 0.0138 - accuracy: 0.9933\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0138 - accuracy: 0.9933\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.0135 - accuracy: 0.9933\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.0136 - accuracy: 0.9933\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0135 - accuracy: 0.9933\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0136 - accuracy: 0.9900\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.0133 - accuracy: 0.9933\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 84us/sample - loss: 0.0134 - accuracy: 0.9933\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 77us/sample - loss: 0.0132 - accuracy: 0.9933\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.0128 - accuracy: 0.9933\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.0132 - accuracy: 0.9933\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0129 - accuracy: 0.9933\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0126 - accuracy: 0.9933\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.0128 - accuracy: 0.9933\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 81us/sample - loss: 0.0126 - accuracy: 0.9933\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 89us/sample - loss: 0.0126 - accuracy: 0.9967\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 75us/sample - loss: 0.0125 - accuracy: 0.9933\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 73us/sample - loss: 0.0121 - accuracy: 0.9933\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.0122 - accuracy: 0.9933\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 82us/sample - loss: 0.0124 - accuracy: 0.9933\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 85us/sample - loss: 0.0123 - accuracy: 0.9933\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0118 - accuracy: 0.9933\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.0119 - accuracy: 0.9933\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.0118 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a929e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "#inputs\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "#hidden\n",
    "model2.add(Dense(30, activation='relu'))\n",
    "model2.add(Dense(25, activation='relu'))\n",
    "\n",
    "#output\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile\n",
    "model2.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#implementing myCallback function\n",
    "h2 = model2.fit(X, y, epochs=500, callbacks=[myCallback()])\n",
    "h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Compare\n",
    "\n",
    "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
    "\n",
    "\n",
    "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.17.2-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 851 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.3 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (0.22.2.post1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (46.1.3.post20200330)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (1.0.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from mlxtend) (1.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from pandas>=0.24.2->mlxtend) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/thisthing/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->mlxtend) (1.14.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thisthing/lib/python3.7/site-packages/mlxtend/plotting/decision_regions.py:249: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
      "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do Not change anything in this cell\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
    "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
    "\n",
    "    ax = plt.subplot(1,2, grd)\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
    "\n",
    "Why might this property be useful in more complex data such as images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "#### Why does the Perceptron (model1) only achieve ~70% accuracy?\n",
    " - The Model achieves 70% accuracy because there is only one dense layer with a single neuron, which can only describe a linear relationship in the model.\n",
    "\n",
    "#### What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y?\n",
    " - The hidden layer is the architectural property. This allows it to learn the non-linear relationship between the data.\n",
    " \n",
    "#### Why might this property be useful in more complex data such as images?\n",
    " - This is useful because images are full of non-linear relationships. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "205   52    1   0       128   255    0        1      161      1      0.0   \n",
       "276   58    1   0       146   218    0        1      105      0      2.0   \n",
       "24    40    1   3       140   199    0        1      178      1      1.4   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "228   59    1   3       170   288    0        0      159      0      0.2   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "205      2   1     3       0  \n",
       "276      1   1     3       0  \n",
       "24       2   0     3       1  \n",
       "1        0   0     2       1  \n",
       "228      1   0     3       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26098049  0.68100522 -0.93851463 -0.20696359  0.1688269  -0.41763453\n",
      "   0.89896224  0.49647834  1.43548113 -0.89686172  0.97635214  0.26508221\n",
      "   1.12302895]\n",
      " [ 0.40075247  0.68100522 -0.93851463  0.82106867 -0.54621594 -0.41763453\n",
      "   0.89896224 -1.95242994 -0.69663055  0.82852939 -0.64911323  0.26508221\n",
      "   1.12302895]\n",
      " [-1.58444641  0.68100522  1.97312292  0.47839125 -0.91340011 -0.41763453\n",
      "   0.89896224  1.23989692  1.43548113  0.31091206  0.97635214 -0.71442887\n",
      "   1.12302895]\n",
      " [-1.91531289  0.68100522  1.00257707 -0.09273778  0.07219949 -0.41763453\n",
      "   0.89896224  1.63347147 -0.69663055  2.12257273 -2.27457861 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.5110413   0.68100522  1.97312292  2.19177836  0.80656782 -0.41763453\n",
      "  -1.00583187  0.40901733 -0.69663055 -0.7243226  -0.64911323 -0.71442887\n",
      "   1.12302895]\n",
      " [ 1.06248543 -1.46841752 -0.93851463  2.7629074   1.52161066 -0.41763453\n",
      "   0.89896224  0.19036481  1.43548113 -0.89686172  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [-0.48155814 -1.46841752 -0.93851463 -1.23499586  0.14950142 -0.41763453\n",
      "  -1.00583187  0.40901733 -0.69663055 -0.89686172  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [-1.47415758 -1.46841752  0.03203122 -0.3211894   1.1544265  -0.41763453\n",
      "   0.89896224  0.58393935 -0.69663055 -0.89686172  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.84190778  0.68100522  1.00257707 -0.09273778 -0.29498467 -0.41763453\n",
      "   0.89896224 -0.15947923 -0.69663055  0.65599028 -0.64911323  2.22410436\n",
      "   1.12302895]\n",
      " [-1.25357993  0.68100522 -0.93851463  0.02148802  0.01422304  2.394438\n",
      "  -1.00583187 -0.29067075  1.43548113 -0.81059216 -0.64911323  3.20361543\n",
      "   1.12302895]]\n"
     ]
    }
   ],
   "source": [
    "#scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/5\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 0.6941 - mse: 0.2505 - mae: 0.4976 - accuracy: 0.5050\n",
      "Epoch 2/5\n",
      "303/303 [==============================] - 0s 131us/sample - loss: 0.6619 - mse: 0.2344 - mae: 0.4830 - accuracy: 0.6898\n",
      "Epoch 3/5\n",
      "303/303 [==============================] - 0s 94us/sample - loss: 0.6405 - mse: 0.2239 - mae: 0.4708 - accuracy: 0.7327\n",
      "Epoch 4/5\n",
      "303/303 [==============================] - 0s 112us/sample - loss: 0.6189 - mse: 0.2133 - mae: 0.4583 - accuracy: 0.7591\n",
      "Epoch 5/5\n",
      "303/303 [==============================] - 0s 102us/sample - loss: 0.5955 - mse: 0.2021 - mae: 0.4440 - accuracy: 0.7723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12e48ff28>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "\n",
    "#declare sequential\n",
    "model = Sequential()\n",
    "\n",
    "#inputs\n",
    "model.add(Dense(13, activation='sigmoid'))\n",
    "\n",
    "#hidden\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "#output\n",
    "model.add(Dense(1, activation='sigmoid')) #softmax run did not work\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy', metrics=['mse', 'mae', 'accuracy'])\n",
    "\n",
    "#fit\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             multiple                  182       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  420       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  775       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  26        \n",
      "=================================================================\n",
      "Total params: 1,403\n",
      "Trainable params: 1,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.5780 - mse: 0.1938 - mae: 0.4331 - accuracy: 0.7822\n",
      "\n",
      "\n",
      "Validation Data Metrics:\n",
      "loss: [0.5780182653921272, 0.19375671, 0.43314955, 0.7821782]\n",
      "mse: 19.375671446323395\n",
      "mae: [0.5780182653921272, 0.19375671, 0.43314955, 0.7821782]\n",
      "accuracy: [0.5780182653921272, 0.19375671, 0.43314955, 0.7821782]\n"
     ]
    }
   ],
   "source": [
    "#for baseline without hyperparams\n",
    "scores = model.evaluate(X, y)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Data Metrics:\")\n",
    "print(f\"{model.metrics_names[0]}: {scores[:]}\")\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")\n",
    "print(f\"{model.metrics_names[2]}: {scores[:]}\")\n",
    "print(f\"{model.metrics_names[3]}: {scores[:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/200\n",
      "303/303 [==============================] - 0s 2ms/sample - loss: 0.2119 - mse: 0.2119 - mae: 0.4463 - accuracy: 0.6799\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.1394 - mse: 0.1394 - mae: 0.3307 - accuracy: 0.8251\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 180us/sample - loss: 0.1185 - mse: 0.1185 - mae: 0.2795 - accuracy: 0.8581\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 250us/sample - loss: 0.1075 - mse: 0.1075 - mae: 0.2512 - accuracy: 0.8581\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 302us/sample - loss: 0.1015 - mse: 0.1015 - mae: 0.2322 - accuracy: 0.8680\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 233us/sample - loss: 0.0960 - mse: 0.0960 - mae: 0.2203 - accuracy: 0.8812\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 295us/sample - loss: 0.0914 - mse: 0.0914 - mae: 0.2096 - accuracy: 0.8845\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.1988 - accuracy: 0.8878\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 323us/sample - loss: 0.0835 - mse: 0.0835 - mae: 0.1966 - accuracy: 0.9043\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 289us/sample - loss: 0.0783 - mse: 0.0783 - mae: 0.1840 - accuracy: 0.9076\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 257us/sample - loss: 0.0754 - mse: 0.0754 - mae: 0.1782 - accuracy: 0.9175\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.0724 - mse: 0.0724 - mae: 0.1712 - accuracy: 0.9076\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 280us/sample - loss: 0.0702 - mse: 0.0702 - mae: 0.1716 - accuracy: 0.9208\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 395us/sample - loss: 0.0659 - mse: 0.0659 - mae: 0.1655 - accuracy: 0.9241\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 279us/sample - loss: 0.0647 - mse: 0.0647 - mae: 0.1591 - accuracy: 0.9208\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.0596 - mse: 0.0596 - mae: 0.1529 - accuracy: 0.9274\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 292us/sample - loss: 0.0588 - mse: 0.0588 - mae: 0.1534 - accuracy: 0.9373\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 208us/sample - loss: 0.0550 - mse: 0.0550 - mae: 0.1407 - accuracy: 0.9340\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.0511 - mse: 0.0511 - mae: 0.1371 - accuracy: 0.9439\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 204us/sample - loss: 0.0496 - mse: 0.0496 - mae: 0.1333 - accuracy: 0.9505\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 396us/sample - loss: 0.0465 - mse: 0.0465 - mae: 0.1317 - accuracy: 0.9571\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 308us/sample - loss: 0.0457 - mse: 0.0457 - mae: 0.1278 - accuracy: 0.9406\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 301us/sample - loss: 0.0441 - mse: 0.0441 - mae: 0.1255 - accuracy: 0.9571\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 227us/sample - loss: 0.0400 - mse: 0.0400 - mae: 0.1190 - accuracy: 0.9670\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 246us/sample - loss: 0.0379 - mse: 0.0379 - mae: 0.1166 - accuracy: 0.9736\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 233us/sample - loss: 0.0354 - mse: 0.0354 - mae: 0.1092 - accuracy: 0.9703\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 222us/sample - loss: 0.0329 - mse: 0.0329 - mae: 0.1056 - accuracy: 0.9802\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 270us/sample - loss: 0.0306 - mse: 0.0306 - mae: 0.0993 - accuracy: 0.9835\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 313us/sample - loss: 0.0294 - mse: 0.0294 - mae: 0.0965 - accuracy: 0.9868\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 249us/sample - loss: 0.0289 - mse: 0.0289 - mae: 0.0903 - accuracy: 0.9802\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 286us/sample - loss: 0.0258 - mse: 0.0258 - mae: 0.0884 - accuracy: 0.9835\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 278us/sample - loss: 0.0256 - mse: 0.0256 - mae: 0.0878 - accuracy: 0.9868\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 310us/sample - loss: 0.0230 - mse: 0.0230 - mae: 0.0831 - accuracy: 0.9835\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 342us/sample - loss: 0.0221 - mse: 0.0221 - mae: 0.0789 - accuracy: 0.9868\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 324us/sample - loss: 0.0209 - mse: 0.0209 - mae: 0.0757 - accuracy: 0.9868\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.0192 - mse: 0.0192 - mae: 0.0709 - accuracy: 0.9901\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 287us/sample - loss: 0.0178 - mse: 0.0178 - mae: 0.0676 - accuracy: 0.9901\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 285us/sample - loss: 0.0173 - mse: 0.0173 - mae: 0.0681 - accuracy: 0.9901\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 250us/sample - loss: 0.0162 - mse: 0.0162 - mae: 0.0637 - accuracy: 0.9934\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 324us/sample - loss: 0.0158 - mse: 0.0158 - mae: 0.0625 - accuracy: 0.9934\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 318us/sample - loss: 0.0139 - mse: 0.0139 - mae: 0.0573 - accuracy: 0.9934\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 315us/sample - loss: 0.0138 - mse: 0.0138 - mae: 0.0576 - accuracy: 0.9934\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.0131 - mse: 0.0131 - mae: 0.0552 - accuracy: 0.9934\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 294us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0515 - accuracy: 0.9934\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.0120 - mse: 0.0120 - mae: 0.0501 - accuracy: 0.9934\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 275us/sample - loss: 0.0128 - mse: 0.0128 - mae: 0.0517 - accuracy: 0.9934\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 281us/sample - loss: 0.0110 - mse: 0.0110 - mae: 0.0456 - accuracy: 0.9934\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 309us/sample - loss: 0.0105 - mse: 0.0105 - mae: 0.0461 - accuracy: 0.9934\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 300us/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0448 - accuracy: 0.9934\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 193us/sample - loss: 0.0095 - mse: 0.0095 - mae: 0.0425 - accuracy: 0.9934\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 191us/sample - loss: 0.0093 - mse: 0.0093 - mae: 0.0435 - accuracy: 0.9934\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 190us/sample - loss: 0.0091 - mse: 0.0091 - mae: 0.0420 - accuracy: 0.9934\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.0082 - mse: 0.0082 - mae: 0.0391 - accuracy: 0.9934\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 218us/sample - loss: 0.0077 - mse: 0.0077 - mae: 0.0389 - accuracy: 0.9934\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 315us/sample - loss: 0.0073 - mse: 0.0073 - mae: 0.0371 - accuracy: 0.9967\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 286us/sample - loss: 0.0071 - mse: 0.0071 - mae: 0.0358 - accuracy: 0.9934\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 314us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0342 - accuracy: 0.9967\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 184us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0349 - accuracy: 0.9967\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 241us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0332 - accuracy: 0.9967\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 210us/sample - loss: 0.0059 - mse: 0.0059 - mae: 0.0315 - accuracy: 0.9967\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 164us/sample - loss: 0.0058 - mse: 0.0058 - mae: 0.0305 - accuracy: 0.9967\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 180us/sample - loss: 0.0056 - mse: 0.0056 - mae: 0.0286 - accuracy: 0.9967\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 179us/sample - loss: 0.0058 - mse: 0.0058 - mae: 0.0286 - accuracy: 0.9967\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 198us/sample - loss: 0.0061 - mse: 0.0061 - mae: 0.0302 - accuracy: 0.9967\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 184us/sample - loss: 0.0055 - mse: 0.0055 - mae: 0.0280 - accuracy: 0.9967\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 194us/sample - loss: 0.0050 - mse: 0.0050 - mae: 0.0252 - accuracy: 0.9967\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 191us/sample - loss: 0.0049 - mse: 0.0049 - mae: 0.0251 - accuracy: 0.9967\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 233us/sample - loss: 0.0048 - mse: 0.0048 - mae: 0.0237 - accuracy: 0.9967\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 296us/sample - loss: 0.0047 - mse: 0.0047 - mae: 0.0235 - accuracy: 0.9967\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 315us/sample - loss: 0.0046 - mse: 0.0046 - mae: 0.0230 - accuracy: 0.9967\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 288us/sample - loss: 0.0046 - mse: 0.0046 - mae: 0.0226 - accuracy: 0.9967\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 215us/sample - loss: 0.0045 - mse: 0.0045 - mae: 0.0217 - accuracy: 0.9967\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 197us/sample - loss: 0.0044 - mse: 0.0044 - mae: 0.0213 - accuracy: 0.9967\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 179us/sample - loss: 0.0044 - mse: 0.0044 - mae: 0.0211 - accuracy: 0.9967\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 203us/sample - loss: 0.0043 - mse: 0.0043 - mae: 0.0204 - accuracy: 0.9967\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 181us/sample - loss: 0.0042 - mse: 0.0042 - mae: 0.0198 - accuracy: 0.9967\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 182us/sample - loss: 0.0042 - mse: 0.0042 - mae: 0.0198 - accuracy: 0.9967\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 208us/sample - loss: 0.0042 - mse: 0.0042 - mae: 0.0191 - accuracy: 0.9967\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 230us/sample - loss: 0.0041 - mse: 0.0041 - mae: 0.0190 - accuracy: 0.9967\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 290us/sample - loss: 0.0041 - mse: 0.0041 - mae: 0.0182 - accuracy: 0.9967\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 307us/sample - loss: 0.0040 - mse: 0.0040 - mae: 0.0181 - accuracy: 0.9967\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 324us/sample - loss: 0.0041 - mse: 0.0041 - mae: 0.0179 - accuracy: 0.9967\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 295us/sample - loss: 0.0040 - mse: 0.0040 - mae: 0.0175 - accuracy: 0.9967\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 254us/sample - loss: 0.0040 - mse: 0.0040 - mae: 0.0172 - accuracy: 0.9967\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 388us/sample - loss: 0.0040 - mse: 0.0040 - mae: 0.0168 - accuracy: 0.9967\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 326us/sample - loss: 0.0039 - mse: 0.0039 - mae: 0.0167 - accuracy: 0.9967\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.0039 - mse: 0.0039 - mae: 0.0160 - accuracy: 0.9967\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 307us/sample - loss: 0.0039 - mse: 0.0039 - mae: 0.0161 - accuracy: 0.9967\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 282us/sample - loss: 0.0038 - mse: 0.0038 - mae: 0.0158 - accuracy: 0.9967\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 346us/sample - loss: 0.0038 - mse: 0.0038 - mae: 0.0153 - accuracy: 0.9967\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 281us/sample - loss: 0.0038 - mse: 0.0038 - mae: 0.0150 - accuracy: 0.9967\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 299us/sample - loss: 0.0038 - mse: 0.0038 - mae: 0.0151 - accuracy: 0.9967\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 326us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0147 - accuracy: 0.9967\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 290us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0145 - accuracy: 0.9967\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 283us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0143 - accuracy: 0.9967\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0141 - accuracy: 0.9967\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 302us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0138 - accuracy: 0.9967\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 273us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0138 - accuracy: 0.9967\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 254us/sample - loss: 0.0037 - mse: 0.0037 - mae: 0.0134 - accuracy: 0.9967\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 282us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0134 - accuracy: 0.9967\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 322us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0131 - accuracy: 0.9967\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 339us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0130 - accuracy: 0.9967\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0128 - accuracy: 0.9967\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 412us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0127 - accuracy: 0.9967\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 0s 276us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0124 - accuracy: 0.9967\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0123 - accuracy: 0.9967\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 360us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0121 - accuracy: 0.9967\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0120 - accuracy: 0.9967\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 314us/sample - loss: 0.0036 - mse: 0.0036 - mae: 0.0120 - accuracy: 0.9967\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 284us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0118 - accuracy: 0.9967\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 269us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0116 - accuracy: 0.9967\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 311us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0114 - accuracy: 0.9967\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 308us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0112 - accuracy: 0.9967\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 281us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0112 - accuracy: 0.9967\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 331us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0110 - accuracy: 0.9967\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 296us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0110 - accuracy: 0.9967\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0108 - accuracy: 0.9967\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 324us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0107 - accuracy: 0.9967\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 242us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0106 - accuracy: 0.9967\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 267us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0107 - accuracy: 0.9967\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 309us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0104 - accuracy: 0.9967\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 329us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0104 - accuracy: 0.9967\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 301us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0101 - accuracy: 0.9967\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 299us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0101 - accuracy: 0.9967\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 244us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0100 - accuracy: 0.9967\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 296us/sample - loss: 0.0035 - mse: 0.0035 - mae: 0.0098 - accuracy: 0.9967\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 246us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0098 - accuracy: 0.9967\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 440us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0097 - accuracy: 0.9967\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 271us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0097 - accuracy: 0.9967\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 300us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0095 - accuracy: 0.9967\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 305us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0094 - accuracy: 0.9967\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0094 - accuracy: 0.9967\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 236us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0093 - accuracy: 0.9967\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 258us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0092 - accuracy: 0.9967\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 251us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0091 - accuracy: 0.9967\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 256us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0091 - accuracy: 0.9967\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 369us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0090 - accuracy: 0.9967\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 300us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0089 - accuracy: 0.9967\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 291us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0090 - accuracy: 0.9967\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 318us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0088 - accuracy: 0.9967\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 219us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0087 - accuracy: 0.9967\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0087 - accuracy: 0.9967\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 319us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0086 - accuracy: 0.9967\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 236us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0085 - accuracy: 0.9967\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 237us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0084 - accuracy: 0.9967\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 323us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0084 - accuracy: 0.9967\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 289us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0083 - accuracy: 0.9967  \n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0082 - accuracy: 0.9967\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0082 - accuracy: 0.9967\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0081 - accuracy: 0.9967\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 310us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0080 - accuracy: 0.9967\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 271us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0080 - accuracy: 0.9967\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 241us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0079 - accuracy: 0.9967\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 214us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0079 - accuracy: 0.9967\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 222us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0078 - accuracy: 0.9967\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 232us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0078 - accuracy: 0.9967\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 239us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0077 - accuracy: 0.9967\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 261us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0077 - accuracy: 0.9967\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 257us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0076 - accuracy: 0.9967\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 274us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0076 - accuracy: 0.9967\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 307us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0075 - accuracy: 0.9967\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 310us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0076 - accuracy: 0.9967\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0075 - accuracy: 0.9967\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 272us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0074 - accuracy: 0.9967\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 247us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0073 - accuracy: 0.9967\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 229us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0073 - accuracy: 0.9967\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 263us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0072 - accuracy: 0.9967\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 257us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0072 - accuracy: 0.9967\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 253us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0073 - accuracy: 0.9967\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 330us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0072 - accuracy: 0.9967\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 302us/sample - loss: 0.0034 - mse: 0.0034 - mae: 0.0071 - accuracy: 0.9967\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 360us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0070 - accuracy: 0.9967  \n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 341us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0069 - accuracy: 0.9967\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 293us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0069 - accuracy: 0.9967\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 257us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0069 - accuracy: 0.9967\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 228us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0068 - accuracy: 0.9967\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 303us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0068 - accuracy: 0.9967\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 322us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0067 - accuracy: 0.9967\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 286us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0067 - accuracy: 0.9967\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 277us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0067 - accuracy: 0.9967\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0066 - accuracy: 0.9967\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 286us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0066 - accuracy: 0.9967\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 239us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0066 - accuracy: 0.9967\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 239us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0065 - accuracy: 0.9967\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 247us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0065 - accuracy: 0.9967\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 260us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0064 - accuracy: 0.9967\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 229us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0064 - accuracy: 0.9967\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 252us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0064 - accuracy: 0.9967\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 230us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0064 - accuracy: 0.9967\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 247us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0063 - accuracy: 0.9967  \n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 257us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0063 - accuracy: 0.9967\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 293us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0062 - accuracy: 0.9967\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 324us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0062 - accuracy: 0.9967\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 255us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0062 - accuracy: 0.9967  \n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 309us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0062 - accuracy: 0.9967\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 265us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0061 - accuracy: 0.9967\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 239us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0061 - accuracy: 0.9967\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 248us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0061 - accuracy: 0.9967\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 333us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0060 - accuracy: 0.9967\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 337us/sample - loss: 0.0033 - mse: 0.0033 - mae: 0.0060 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12e62a390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
    "Use the Heart Disease Dataset (binary classification). \n",
    "Use an appropriate loss function for a binary classification task. \n",
    "Use an appropriate activation function on the final layer of your network. \n",
    "Train your model using verbose output for ease of grading. \n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. \n",
    "(for at least two hyperparameters) When hyperparameter tuning, \n",
    "show you work by adding code cells for each new experiment. \n",
    "Report the accuracy for each combination of hyperparameters as you test them so \n",
    "that we can easily see which resulted in the highest accuracy. \n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section.\n",
    "\n",
    "Most important:\n",
    "\n",
    "batch_size\n",
    "training epochs\n",
    "optimization algorithms\n",
    "learning rate\n",
    "momentum\n",
    "activation functions\n",
    "dropout regularization\n",
    "number of neurons in the hidden layer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#model with hyperparams\n",
    "#hyperparameter tuning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Important Hyperparameters\n",
    "inputs = X.shape[1]\n",
    "epochs = 200\n",
    "#every time you see 10 data points, update the weights\n",
    "batch_size = 10 \n",
    "\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(inputs,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #activation output for binary\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae', 'accuracy'])\n",
    "\n",
    "# Fit Model\n",
    "model.fit(X, y, \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7955191373825073 using {'batch_size': 10, 'epochs': 70}\n",
      "Means: 0.7955191373825073, Stdev: 0.03151855220851633 with: {'batch_size': 10, 'epochs': 70}\n",
      "Means: 0.7626775979995728, Stdev: 0.038121405831096196 with: {'batch_size': 20, 'epochs': 70}\n",
      "Means: 0.7159016370773316, Stdev: 0.060134209330261736 with: {'batch_size': 40, 'epochs': 70}\n",
      "Means: 0.6593442559242249, Stdev: 0.09546783280192245 with: {'batch_size': 60, 'epochs': 70}\n",
      "Means: 0.6830054521560669, Stdev: 0.07445470431746028 with: {'batch_size': 80, 'epochs': 70}\n",
      "Means: 0.5477595508098603, Stdev: 0.07590228264405897 with: {'batch_size': 100, 'epochs': 70}\n"
     ]
    }
   ],
   "source": [
    "#iterating over batch size...\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    #create\n",
    "    model = Sequential()\n",
    "    #input\n",
    "    model.add(Dense(15, input_dim=13, activation='relu'))\n",
    "    #output\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#keras\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [70]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8186338782310486 using {'batch_size': 10, 'epochs': 120}\n",
      "Means: 0.6933333396911621, Stdev: 0.055635180367743585 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7688524603843689, Stdev: 0.028465167613369015 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.8089071035385131, Stdev: 0.04113692262879547 with: {'batch_size': 10, 'epochs': 70}\n",
      "Means: 0.7757923483848572, Stdev: 0.04616486650721591 with: {'batch_size': 10, 'epochs': 100}\n",
      "Means: 0.8186338782310486, Stdev: 0.04923325681787224 with: {'batch_size': 10, 'epochs': 120}\n",
      "Means: 0.8018579244613647, Stdev: 0.03021933648769745 with: {'batch_size': 10, 'epochs': 150}\n",
      "Means: 0.7854098320007324, Stdev: 0.047810179446058254 with: {'batch_size': 10, 'epochs': 170}\n",
      "Means: 0.8185245990753174, Stdev: 0.04281601183241412 with: {'batch_size': 10, 'epochs': 190}\n"
     ]
    }
   ],
   "source": [
    "#epochs, tune last\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [20, 40, 70, 100, 120, 150, 170, 190]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thisthing (Python3)",
   "language": "python",
   "name": "thisthing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
